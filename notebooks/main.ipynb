{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3781f022",
      "metadata": {
        "id": "3781f022"
      },
      "source": [
        "<h1>ü§ñ MLAI Workshop #03</h1>\n",
        "\n",
        "<h2>Agenda</h2>\n",
        "\n",
        "0.   Summary of previous workshops: reviewe hypothesis spaces, data generation, and optimization, using MLPs to understand interpolation and extrapolation behaviour.\n",
        "1.   Problem formulation: explore different ways of defining a task and structuring inputs (e.g. coordinates, rasters, graphs) - and discuss how this influences what models can learn.\n",
        "2.   Design, train, and evaluate: use a model for spiral classification, evaluate robustness to noise and missing data, and investigate decision boundaries and learned representations."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Section 0. Previously On...</h2>"
      ],
      "metadata": {
        "id": "Yd8R1dmoq-Z6"
      },
      "id": "Yd8R1dmoq-Z6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 0A. The Learning Problem</h3>\n",
        "\n",
        "In the first workshop we introduced the concept of the hypothesis, dataset, and optimization spaces - we explored how each of these influence the final solution $\\hat{f}$ we obtain. We spent most of the workshop using hand-crafted hypothesis spaces.\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://github.com/nextgenerationgraduatesprogram/nextgen25-mlai-workshop03/blob/main/notebooks/...?raw=1\" height=\"400\"/>\n",
        "    <p><em>Figure 1. Illustration of the hypothesis, dataset, optimization, and target spaces considered in the learning problem.</em></p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "TqDHIBKLsKse"
      },
      "id": "TqDHIBKLsKse"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 0B. Universal Function Approximation</h3>\n",
        "\n",
        "In the second workshop we started to address the challenges of using a hand-crafted hypothesis space, explored how we could design universal function approximators, and gained some experience training simple multi-layer perceptrons.\n",
        "\n",
        "> Our final solution is a function of the Hypothesis, Dataset, and Optimization\n"
      ],
      "metadata": {
        "id": "e-DD7IdAsJKn"
      },
      "id": "e-DD7IdAsJKn"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# observe some data using a noisy observation process\n",
        "def observe_noisy(f, x):\n",
        "  # Input noise ~ N(mean=0.05, std=0.02)\n",
        "  x_noise = torch.randn_like(x) * 0.02 + 0.05\n",
        "  x_measure = x + x_noise\n",
        "\n",
        "   # Evaluate the (noisy) inputs\n",
        "  y_pred = f(x_measure)\n",
        "\n",
        "  # Output noise ~ N(mean=-0.05, std=0.08)\n",
        "  y_noise = torch.randn_like(y_pred) * 0.08 - 0.05\n",
        "  y_obs = y_pred + y_noise\n",
        "\n",
        "  return y_obs"
      ],
      "metadata": {
        "id": "CLUvgQ4V_g2s"
      },
      "id": "CLUvgQ4V_g2s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable\n",
        "\n",
        "# create a dataset\n",
        "class Dataset:\n",
        "  def __init__(self, f: Callable, a: float, b: float, N: int = 100):\n",
        "    super(Dataset, self).__init__()\n",
        "\n",
        "    # Sample x uniformly in [a, b], shape [N,1]\n",
        "    self.x = torch.rand(N, 1) * (b - a) + a\n",
        "\n",
        "    # Observe f(x) through noise process, also [N,1]\n",
        "    self.y = observe_noisy(f, self.x)"
      ],
      "metadata": {
        "id": "1fif9AB-_g6u"
      },
      "id": "1fif9AB-_g6u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# define a target function i.e. your data generating process\n",
        "f = lambda x: torch.exp(-x**2) * torch.sin(5.8 * torch.pi * x + 0.41)\n",
        "\n",
        "# define a dataset with your function\n",
        "dataset = Dataset(f, a=0, b=1, N=200)\n",
        "\n",
        "# visualize the observations\n",
        "fig, ax = plt.subplots(figsize=(8,3))\n",
        "ax.scatter(dataset.x, dataset.y, s=6, label=\"observations\")\n",
        "ax.set_xlim(dataset.x.min(), dataset.x.max())\n",
        "ax.legend(loc=\"best\")\n",
        "ax.set_xlabel(\"x_meas\")\n",
        "ax.set_ylabel(\"y_obs\")"
      ],
      "metadata": {
        "id": "sM624eBF_g9J"
      },
      "id": "sM624eBF_g9J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# define a layer of perceptrons as a building block\n",
        "class PerceptronLayer(nn.Module):\n",
        "  def __init__(self, input_dim: int, output_dim: int, act: bool = True):\n",
        "    super(PerceptronLayer, self).__init__()\n",
        "    self.fc = nn.Linear(input_dim, output_dim)\n",
        "    self.act = nn.ReLU() if act else nn.Identity()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.act(self.fc(x))\n",
        "    return x\n",
        "\n",
        "# create a flexible hypothesis space using an MLP\n",
        "class MultiLayerPerceptron(nn.Module):\n",
        "  def __init__(self, hidden_layers: int = 0, hidden_dim: int = 1, input_dim: int = 1, output_dim: int = 1):\n",
        "    super(MultiLayerPerceptron, self).__init__()\n",
        "    modules = [PerceptronLayer(input_dim, hidden_dim)] # input layer\n",
        "    for _ in range(hidden_layers): modules.append(PerceptronLayer(hidden_dim, hidden_dim)) # hidden layers\n",
        "    modules.append(PerceptronLayer(hidden_dim, output_dim, act=False)) # output layer (no activation)\n",
        "    self.layers = nn.ModuleList(modules) # store layers\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "DNCcOb1d_oGg"
      },
      "id": "DNCcOb1d_oGg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# define a training loop\n",
        "def training_loop(model, optimizer, loss_fn, dataset, steps):\n",
        "  losses = []\n",
        "  with tqdm(range(steps)) as pbar:\n",
        "    for idx in pbar:\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(dataset.x)\n",
        "      loss = loss_fn(dataset.y, y_pred)\n",
        "      losses.append(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      pbar.set_description(f\"loss: {loss.item():.3f}\")\n",
        "    return model, torch.tensor(losses)\n",
        "\n",
        "# define some functions for plotting our results\n",
        "def plot_loss_curve(losses):\n",
        "    fig, ax = plt.subplots(figsize=(8,3))\n",
        "    ax.plot(losses, label=\"loss\")\n",
        "    ax.set_xlim(left=0, right=len(losses)-1)\n",
        "    ax.set_xlabel(\"Iteration\")\n",
        "    ax.set_ylabel(\"Loss (MSE)\")\n",
        "    ax.set_title(\"Loss Curve\")\n",
        "    ax.grid(True, alpha=0.50)\n",
        "    ax.legend()\n",
        "    return fig, ax\n",
        "\n",
        "def plot_predictions(model, dataset, ax = None):\n",
        "    if ax is None: fig, ax = plt.subplots(figsize=(8,3))\n",
        "    with torch.no_grad():\n",
        "        ax.scatter(dataset.x, model(dataset.x), s=4, label=\"predictions\")\n",
        "        ax.scatter(dataset.x, dataset.y, s=4, label=\"observations\")\n",
        "    ax.set_xlim(left=dataset.x.min(), right=dataset.x.max())\n",
        "    ax.grid(True, alpha=0.50)\n",
        "    ax.legend(loc=\"best\")\n",
        "    return ax"
      ],
      "metadata": {
        "id": "pvJ_FWL-_oJI"
      },
      "id": "pvJ_FWL-_oJI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When training our models we generally want our setup to have several properties:\n",
        "\n",
        "\n",
        "1.   We want the dataset to sufficiently represent the data generating process.\n",
        "2.   We want the hypothesis space to be large enough to accurately approximate the dataset.\n",
        "3.   We need our optimizer to be capable of finding a suitable set of solutions.\n",
        "\n"
      ],
      "metadata": {
        "id": "WSmKl1KWAKe5"
      },
      "id": "WSmKl1KWAKe5"
    },
    {
      "cell_type": "code",
      "source": [
        "# train a model\n",
        "dataset = Dataset(f, a=0, b=1, N=200)\n",
        "model = MultiLayerPerceptron(hidden_layers=0, hidden_dim=10)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "model, losses = training_loop(model, optimizer, loss_fn, dataset, steps=500)"
      ],
      "metadata": {
        "id": "Ujoidm8j_xII"
      },
      "id": "Ujoidm8j_xII",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curve(losses)\n",
        "plot_predictions(model, dataset)"
      ],
      "metadata": {
        "id": "AH0uat33ADxE"
      },
      "id": "AH0uat33ADxE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 0C. Interpolation Error</h3>\n",
        "\n",
        "We also investigated some of the challenges inherent in learning from data in terms of interpolation and extrapolation performance. We saw that our interpolation error is typically bounded by our ability to resolve changes in the data manifold."
      ],
      "metadata": {
        "id": "wnp9zEcJ_fhv"
      },
      "id": "wnp9zEcJ_fhv"
    },
    {
      "cell_type": "code",
      "source": [
        "# define your domain\n",
        "dataset = Dataset(f, a=0, b=1, N=500)\n",
        "\n",
        "# lets explore how well it interpolates by erasing a region\n",
        "x_min, x_max = 0.45, 0.60\n",
        "keep_idxs = (dataset.x < x_min) | (dataset.x > x_max)\n",
        "dataset.x = dataset.x[keep_idxs].unsqueeze(-1)\n",
        "dataset.y = dataset.y[keep_idxs].unsqueeze(-1)\n",
        "\n",
        "# train a model\n",
        "model = MultiLayerPerceptron(hidden_layers=2, hidden_dim=30) # 0 hidden layers / 1 perceptrons\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "model, losses = training_loop(model, optimizer, loss_fn, dataset, steps=500)\n",
        "\n",
        "# plot the results\n",
        "plot_loss_curve(losses)\n",
        "ax = plot_predictions(model, dataset)\n",
        "\n",
        "# see how well it interpolates\n",
        "dataset_interp = Dataset(f, a=x_min, b=x_max, N=100)\n",
        "ax = plot_predictions(model, dataset_interp, ax)\n",
        "ax.set_xlim(0, 1)"
      ],
      "metadata": {
        "id": "C49lq_SzA_wg"
      },
      "id": "C49lq_SzA_wg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 0D. Extrapolation Error</h3>\n",
        "\n",
        "Extending this to extrapolation (data outside the convex hull of the training distribution), without data to constrain the behaviour of the function the model typically exhibited poor generalization.\n",
        "\n",
        "For perfect generalization we would require our network to have learned the function governing the data generating process; this is typically a tall-order for extremely flexible hypothesis spaces. The representational capacity of neural networks is typically focussed on resolving the curvature of the dataset manifold - with more suitably constrained hypothesis spaces (i.e. different inductive biases inherent in our choice of architecture) we may be able to enforce some stronger generalization garuntees."
      ],
      "metadata": {
        "id": "QUvK16t2A_5k"
      },
      "id": "QUvK16t2A_5k"
    },
    {
      "cell_type": "code",
      "source": [
        "# define a much broader domain to see how well it extrapolates\n",
        "dataset_extrap = Dataset(f, -0.5, 1.5, 500)\n",
        "\n",
        "# plot the results\n",
        "ax = plot_predictions(model, dataset_extrap)\n",
        "ax.set_xlim(-0.5, 1.5)"
      ],
      "metadata": {
        "id": "w3zPEdpeBAD7"
      },
      "id": "w3zPEdpeBAD7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To remind ourselves of what our multi-layer perceptron is doing, we can investigate the activations of individual neurons. By examining how these units respond to inputs, we begin to uncover the hierarchical feature representations the model is constructing during learning.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0reYaEsuBQVb"
      },
      "id": "0reYaEsuBQVb"
    },
    {
      "cell_type": "code",
      "source": [
        "# lets explore the model\n",
        "model"
      ],
      "metadata": {
        "id": "FZxe3HQ9Bd0O"
      },
      "id": "FZxe3HQ9Bd0O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store\n",
        "activations = {}\n",
        "\n",
        "# define a forward pass hook to grab the outputs\n",
        "def make_hook(name):\n",
        "  def hook(module, input, output):\n",
        "    # detach to avoid keeping the full graph\n",
        "    activations[name] = output.detach().cpu()\n",
        "  return hook\n",
        "\n",
        "# register model hooks to the ReLU outputs\n",
        "for idx, layer in enumerate(model.layers):\n",
        "  if not layer.act._forward_hooks:\n",
        "    layer.act.register_forward_hook(make_hook(f\"layer_{idx}_relu\"))\n",
        "\n",
        "# run a forward pass on region to populate activations\n",
        "x = torch.linspace(-1, 2, steps=1000).unsqueeze(-1)\n",
        "_ = model(x)"
      ],
      "metadata": {
        "id": "vFwDZlQHBd6U"
      },
      "id": "vFwDZlQHBd6U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# which perceptron to inspect\n",
        "layer_index = 1\n",
        "perceptron_indexes = [0, 1, 2, 3, 4]\n",
        "\n",
        "# acts is of shape [N, output_dim]\n",
        "fig, ax = plt.subplots(figsize=(8,3))\n",
        "for perceptron_index in perceptron_indexes:\n",
        "  ax.plot(x, activations[f\"layer_{layer_index}_relu\"][:,perceptron_index], label=f\"layer_{layer_index}_relu:{perceptron_index}\")\n",
        "ax.set_title(f\"Perceptron Activations\")\n",
        "ax.set_xlabel(\"x\")\n",
        "ax.set_ylabel(\"activation\")\n",
        "ax.set_xlim(x.min(), x.max())"
      ],
      "metadata": {
        "id": "RYZHknILBtYE"
      },
      "id": "RYZHknILBtYE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "jZFHEn2Dj5m6"
      },
      "id": "jZFHEn2Dj5m6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Section 1. Up Next... Problem Formulation</h2>\n",
        "\n",
        "So far, we've developed a framework for flexible function approximation, and explored how factors like model capacity, data distribution, and optimization dynamics influence the solutions we learn.\n",
        "\n",
        "In this workshop, we'll explore how to apply this approach to function approximation to different problem settings. Specifically, we'll examine how the structure and representation of our learning task impacts the solutions we can learn, the nature of the task itself, and informs the choice of hypothesis space.\n",
        "\n",
        "We explore this in the following stages:\n",
        "1.   Define a goal.\n",
        "2.   Formulate the learning problem - what are we trying to predict?\n",
        "3.   How should we represent the input?\n",
        "3.   How should we design our hypothesis space?\n",
        "4.   Train, evaluate, and analyse the results.\n"
      ],
      "metadata": {
        "id": "0C9uz_BprXhu"
      },
      "id": "0C9uz_BprXhu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 1A. Goal - Spiral Arm Classification</h3>\n",
        "\n",
        "In earlier examples, we explored problems of the form:\n",
        "\n",
        "\\begin{align*}\n",
        "  f: \\mathcal{X} \\to \\mathcal{Y} \\tag{1.1}\\\\\n",
        "\\end{align*}\n",
        "\n",
        "where $\\mathcal{X} \\in \\mathbb{R}^{1}$ and $\\mathcal{Y} \\in \\mathbb{R}^{1}$. This reflects a simple one-dimensional regression task which is useful for building intuition about aspects of the learning problem."
      ],
      "metadata": {
        "id": "cocWHhueRphQ"
      },
      "id": "cocWHhueRphQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's instead consider the problem setting of classifying the arms of a spiral dataset..."
      ],
      "metadata": {
        "id": "C5sZH-4AeTIO"
      },
      "id": "C5sZH-4AeTIO"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class SpiralDataset():\n",
        "  \"\"\"\n",
        "  Generates a 2D spiral dataset with two arms (binary classification).\n",
        "  Returns:\n",
        "      x: Tensor of shape [2N, 2]\n",
        "      y: Tensor of shape [2N] with labels 0 or 1\n",
        "  \"\"\"\n",
        "  def __init__(self, N: int = 100, noise: float = 0.2, ratio: float = 1.0):\n",
        "    # angle\n",
        "    theta = ratio * 1.5 * np.sqrt(np.random.rand(N)) * 2 * np.pi\n",
        "    r_a = 2 * theta + np.pi / 2\n",
        "    r_b = -2 * theta - np.pi / 2\n",
        "\n",
        "    # Spiral A (label 0)\n",
        "    x_a = np.stack([np.cos(theta) * r_a, np.sin(theta) * r_a], axis=1)\n",
        "    x_a += np.random.randn(N, 2) * noise\n",
        "    y_a = np.zeros(N)\n",
        "\n",
        "    # Spiral B (label 1)\n",
        "    x_b = np.stack([np.cos(theta) * r_b, np.sin(theta) * r_b], axis=1)\n",
        "    x_b += np.random.randn(N, 2) * noise\n",
        "    y_b = np.ones(N)\n",
        "\n",
        "    # format\n",
        "    x = np.concatenate([x_a, x_b], axis=0)\n",
        "    y = np.concatenate([y_a, y_b], axis=0)\n",
        "    self.x = torch.tensor(x, dtype=torch.float32)\n",
        "    self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # for BCE loss\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return self.x.shape[0]\n",
        "\n",
        "  def __getitem__(self, index: int) -> tuple:\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "\n",
        "# define the dataset\n",
        "dataset = SpiralDataset(N=200, noise=0.2)"
      ],
      "metadata": {
        "id": "MNhbVlB4RtKF"
      },
      "id": "MNhbVlB4RtKF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# visualize the dataset\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "\n",
        "# Class A\n",
        "mask0 = dataset.y.squeeze() == 0\n",
        "ax.scatter(dataset.x[mask0, 0], dataset.x[mask0, 1], color=\"darkblue\", label=\"Class A\", edgecolor=\"black\")\n",
        "\n",
        "# Class B\n",
        "mask1 = dataset.y.squeeze() == 1\n",
        "ax.scatter(dataset.x[mask1, 0], dataset.x[mask1, 1], color=\"darkred\", label=\"Class B\", edgecolor=\"black\")\n",
        "\n",
        "ax.set_title(\"Spiral Dataset\")\n",
        "ax.grid(True, alpha=0.50)\n",
        "ax.set_xlabel(r\"$x_{0}$\")\n",
        "ax.set_ylabel(r\"$x_{1}$\")\n",
        "ax.legend(loc=\"best\")"
      ],
      "metadata": {
        "id": "tDsiHo7Nyi_r"
      },
      "id": "tDsiHo7Nyi_r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can investigate the structure of this dataset and observe that we have $400$ samples, and each sample consists of:\n",
        "\n",
        "\\begin{align*}\n",
        "  x \\in \\mathbb{R}^{2}, \\quad y \\in \\{0, 1\\}\n",
        "\\end{align*}\n",
        "\n",
        "where $x = (x_{0}, x_{1})$ represents the position of a sample in cartesian coordinates and $y \\in \\{0, 1\\}$ represents the class label of the position i.e. spiral A (class label 0) or B (class label 1)."
      ],
      "metadata": {
        "id": "x0yF6I--wWL2"
      },
      "id": "x0yF6I--wWL2"
    },
    {
      "cell_type": "code",
      "source": [
        "# how is the data stored?\n",
        "print(f\"x shape: {dataset.x.shape}, dtype: {dataset.x.dtype}\")\n",
        "print(f\"y shape: {dataset.y.shape}, dtype: {dataset.y.dtype}\")\n",
        "print(\"\")\n",
        "\n",
        "# what does a single sample look like?\n",
        "print(f\"X_0 = (x_0, x_1) = {dataset.x[0]}\")\n",
        "print(f\"Y_0 = {dataset.y[0]}\")"
      ],
      "metadata": {
        "id": "KpW7imqdxq1R"
      },
      "id": "KpW7imqdxq1R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 1B. What are we trying to predict?</h3>\n",
        "\n",
        "We are given the goal to classify the spiral arms in our dataset. The first question to ask is:\n",
        "\n",
        "> What do we want our model to learn - and why?\n",
        "\n",
        "There are many valid ways to formulate a learning problem, even with the same data - different formulations represent slight different objectives and interpretations of the problem:\n",
        "\n",
        "*   Do you want to predict which class a point belongs to? This is a very direct formulation.\n",
        "*   Do you want to predict the probability that a point belongs to each class? This probabilistic output allows us to assess confidence and build more interpretable or robust systems.\n",
        "*   Do you want to predict the signed distance to the decision boundary? This provides both classification and geometric insights into the data structure.\n",
        "*   Do you want to predict the polar (angular) coordinate of a point? This provides a structural representation of the curve - that we could also use for classification.\n",
        "*   Do you want to learn to reconstruct the input or discover its latent structure? This allows the model to uncover intrinsic geometry without needing labels, and supports tasks like clustering or generation.\n",
        "\n",
        "Each approach uses the same data and achieves the same goal but approaches it in a slightly different manner.\n",
        "\n",
        "> üí° Choosing the right formulation is a design decision ‚Äî one that aligns your learning system with the actual goal you care about."
      ],
      "metadata": {
        "id": "LlSWpXVRepJM"
      },
      "id": "LlSWpXVRepJM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Let's assume we want to directly predict which class a point belongs to - hard classification. We want some function $f$, that takes in some input $x$, that directly predicts the class label $y \\in \\{0, 1\\}$:\n",
        "\n",
        "\\begin{align*}\n",
        "  f: x \\in ... \\mapsto y \\in \\{0, 1\\}\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "_YjlvnZh5Alk"
      },
      "id": "_YjlvnZh5Alk"
    },
    {
      "cell_type": "code",
      "source": [
        "# our dataset is already stored in this format\n",
        "dataset.y.shape"
      ],
      "metadata": {
        "id": "03-GpPP3-OJs"
      },
      "id": "03-GpPP3-OJs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.unique(dataset.y)"
      ],
      "metadata": {
        "id": "U1uKVK4qLxu2"
      },
      "id": "U1uKVK4qLxu2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí¨ *What is your goal? How have your formulated your learning problem - what specifically are you trying to predict?*"
      ],
      "metadata": {
        "id": "KidVOlfYP4XT"
      },
      "id": "KidVOlfYP4XT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 1C. How should we structure our inputs?</h3>\n",
        "\n",
        "With a clear problem formulation in place, the next decision to make is: how should we represent the input and output data for the model? This is a critical step in the design of machine learning systems that bakes in strong assumptions about:\n",
        "\n",
        "*   What kind of structure we believe the data has.\n",
        "*   What kind of operations we want the model to learn.\n",
        "*   What biases we want to encode into the hypothesis space."
      ],
      "metadata": {
        "id": "7-pAO8L5iZIN"
      },
      "id": "7-pAO8L5iZIN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same underlying data can be represented in many different ways:\n",
        "\n",
        "*   A rasterized image, where we discretize the input space into a grid.\n",
        "*   A point cloud, where each point is a 2D coordinate in continuous space.\n",
        "*   A graph, where edges might encode spatial or similarity relationships.\n",
        "*   A sequence, where each point links to a subsequent point.\n",
        "\n",
        "Each representation encodes different assumptions about the structure of the data."
      ],
      "metadata": {
        "id": "7FwkJS0X9wGg"
      },
      "id": "7FwkJS0X9wGg"
    },
    {
      "cell_type": "code",
      "source": [
        "# rasterize the data\n",
        "def rasterize_by_class(X, y, bins=100):\n",
        "    x0_min, x0_max = X[:,0].min(), X[:,0].max()\n",
        "    x1_min, x1_max = X[:,1].min(), X[:,1].max()\n",
        "\n",
        "    # Separate class 0 and class 1\n",
        "    X0 = X[y.squeeze() == 0]\n",
        "    X1 = X[y.squeeze() == 1]\n",
        "\n",
        "    hist0, _, _ = np.histogram2d(X0[:,0], X0[:,1], bins=bins, range=[[x0_min, x0_max], [x1_min, x1_max]])\n",
        "    hist1, _, _ = np.histogram2d(X1[:,0], X1[:,1], bins=bins, range=[[x0_min, x0_max], [x1_min, x1_max]])\n",
        "\n",
        "    # Normalize histograms to [0,1] for color intensity\n",
        "    hist0 /= hist0.max()\n",
        "    hist1 /= hist1.max()\n",
        "\n",
        "    # Combine into RGB image: Red for class 1, Blue for class 0\n",
        "    rgb = np.zeros((bins, bins, 3))\n",
        "    rgb[..., 0] = hist1.T  # Red channel\n",
        "    rgb[..., 2] = hist0.T  # Blue channel\n",
        "\n",
        "    return rgb, (x0_min, x0_max, x1_min, x1_max)\n",
        "\n",
        "# rasterize\n",
        "rgb, extent = rasterize_by_class(dataset.x, dataset.y, bins=50)\n",
        "\n",
        "# plot image\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "ax.imshow(rgb, extent=extent)\n",
        "ax.set_title(\"Rasterized Spiral (Image-like)\")\n",
        "ax.set_xlabel(\"$x_0$\")\n",
        "ax.set_ylabel(\"$x_1$\")\n",
        "ax.grid(True, alpha=0.50)\n"
      ],
      "metadata": {
        "id": "bf_CAdwR-Mzn"
      },
      "id": "bf_CAdwR-Mzn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import kneighbors_graph\n",
        "import networkx as nx\n",
        "\n",
        "A = kneighbors_graph(dataset.x, n_neighbors=6, mode='connectivity')\n",
        "G = nx.from_scipy_sparse_array(A)\n",
        "\n",
        "pos = {i: (dataset.x[i, 0], dataset.x[i, 1]) for i in range(len(dataset.x))}\n",
        "colors = ['blue' if label == 0 else 'red' for label in dataset.y]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "nx.draw(G, pos, node_color=colors, node_size=20, edge_color='gray', ax=ax)\n",
        "ax.set_title(\"Graph View (k-NN)\")\n",
        "ax.set_xlabel(\"$x_0$\")\n",
        "ax.set_ylabel(\"$x_1$\")\n",
        "ax.grid(True, alpha=0.50)"
      ],
      "metadata": {
        "id": "-efg9L4j-M1r"
      },
      "id": "-efg9L4j-M1r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå For our spiral dataset, we'll assume a point cloud representation, where each input is simply a pair of coordinates in continuous space using Cartesian coordinates:\n",
        "\n",
        "\\begin{align*}\n",
        "  x = (x_{0}, x_{1}) \\in \\mathbb{R}^{2}\n",
        "\\end{align*}\n",
        "\n",
        "This feels like a reasonable representation for our data and encodes a low number of assumptions about the structure of the data (i.e. no grid, no toplogy, no structure) - this also has downsides (i.e. no geometric context). Hence, we have defined our input:\n",
        "\n",
        "\\begin{align*}\n",
        "  f : x \\in \\mathbb{R}^{2} \\mapsto y \\in \\{0, 1\\}\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "y0p2nl0H-Szq"
      },
      "id": "y0p2nl0H-Szq"
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the dataset\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "mask0 = dataset.y.squeeze() == 0\n",
        "ax.scatter(dataset.x[mask0, 0], dataset.x[mask0, 1], color=\"darkblue\", label=\"Class A\", edgecolor=\"black\")\n",
        "mask1 = dataset.y.squeeze() == 1\n",
        "ax.scatter(dataset.x[mask1, 0], dataset.x[mask1, 1], color=\"darkred\", label=\"Class B\", edgecolor=\"black\")\n",
        "ax.set_title(\"Spiral Dataset\")\n",
        "ax.grid(True, alpha=0.50)\n",
        "ax.set_xlabel(r\"$x_{0}$\")\n",
        "ax.set_ylabel(r\"$x_{1}$\")\n",
        "ax.legend(loc=\"best\")"
      ],
      "metadata": {
        "id": "NKart0r-RJjo"
      },
      "id": "NKart0r-RJjo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí¨ *What is your input data? How do you represent your inputs for your model? What assumptions does that representation encode?*"
      ],
      "metadata": {
        "id": "Sn2d6xQTQQWZ"
      },
      "id": "Sn2d6xQTQQWZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might also extend this discussion on how we represent our data to include pre-processing steps such as normalization - these sort of steps adjust the structure and distribution of the input and interacts strongly with aspects of our modelling approach such as parameter initialization, which in turn influence what and how we learn."
      ],
      "metadata": {
        "id": "cmjXi-avlSUS"
      },
      "id": "cmjXi-avlSUS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 1D. Hypothesis Space & Network Structure</h3>\n",
        "\n",
        "So far we have defined how the input and output data is represented. Now we can decide what sort of hypothesis space will we chose to learn this function? Each representation implies a different formulation - and thus different modeling strategies are typically used:\n",
        "\n",
        "*   Images $\\rightarrow$ CNNs, Transformers, etc.\n",
        "*   Point clouds $\\rightarrow$ MLPs, Transformers, etc.\n",
        "*   Graphs $\\rightarrow$ GNNs, MPNNs, Transformers, etc.\n",
        "*   Sequences $\\rightarrow$ RNNs, Transformers, etc.\n",
        "\n",
        "> üí° Data representation is not just about data formatting - its a modeling choice - that has significant impacts on the learning process."
      ],
      "metadata": {
        "id": "MeujwBHbnMSn"
      },
      "id": "MeujwBHbnMSn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå We have been working so far with multi-layer perceptrons, this is a reasonable model class to use in this scenario. We want our MLP, $f$, to take as input the 2D coordinates:\n",
        "\n",
        "\\begin{align*}\n",
        "  x = (x_{0}, x_{1}) \\in \\mathbb{R}^{2}\n",
        "\\end{align*}\n",
        "\n",
        "and output a scalar value representing the class label.\n",
        "\n",
        "\\begin{align*}\n",
        "  y \\in \\{0, 1\\}\n",
        "\\end{align*}\n",
        "\n",
        "We can define a network architecture that achieves this by abstracting our previous model architecture:"
      ],
      "metadata": {
        "id": "AlW2AV8QSXCg"
      },
      "id": "AlW2AV8QSXCg"
    },
    {
      "cell_type": "code",
      "source": [
        "class PointClassificationMultiLayerPerceptron(MultiLayerPerceptron):\n",
        "  def __init__(self, hidden_layers: int = 0, hidden_dim: int = 1):\n",
        "    super(PointClassificationMultiLayerPerceptron, self).__init__(\n",
        "      hidden_layers=hidden_layers,\n",
        "      hidden_dim=hidden_dim,\n",
        "      input_dim=..., # x shape\n",
        "      output_dim=..., # y shape\n",
        "    )"
      ],
      "metadata": {
        "id": "CX28qArC6cfh"
      },
      "id": "CX28qArC6cfh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 1E. Training and evaluating the model</h3>\n",
        "\n",
        "We can go ahead and train our model on our dataset; this might take some tweaking of the model and optimization process."
      ],
      "metadata": {
        "id": "8g73-hUIUF8h"
      },
      "id": "8g73-hUIUF8h"
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(model, optimizer, loss_fn, dataset, steps):\n",
        "  losses = []\n",
        "  with tqdm(range(steps)) as pbar:\n",
        "    for idx in pbar:\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(dataset.x)\n",
        "      loss = loss_fn(y_pred, dataset.y) # input=logits, target=labels\n",
        "      losses.append(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      pbar.set_description(f\"loss: {loss.item():.3f}\")\n",
        "    return model, torch.tensor(losses)\n",
        "\n",
        "def plot_predictions(model, dataset):\n",
        "    # evaluate model\n",
        "    with torch.no_grad():\n",
        "        logits = model(dataset.x)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs >= 0.5).float().cpu().numpy().squeeze()\n",
        "\n",
        "    # Prepare data\n",
        "    x_np = dataset.x.cpu().numpy()\n",
        "\n",
        "    # Plot predictions (color = model prediction)\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    ax.scatter(x_np[:, 0], x_np[:, 1], c=preds, cmap=\"RdBu\", edgecolor=\"k\", label=\"Predictions\")\n",
        "\n",
        "    ax.set_title(\"Model Predictions (Hard Classification)\")\n",
        "    ax.set_xlabel(r\"$x_0$\")\n",
        "    ax.set_ylabel(r\"$x_1$\")\n",
        "    ax.set_aspect(\"equal\")\n",
        "    ax.legend(loc=\"best\")\n",
        "    ax.grid(True, alpha=0.50)\n",
        "    return fig, ax"
      ],
      "metadata": {
        "id": "FgNnX75rZAO0"
      },
      "id": "FgNnX75rZAO0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SpiralDataset(N=100, noise=0.2)\n",
        "model = PointClassificationMultiLayerPerceptron(hidden_layers=0, hidden_dim=10)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "model, losses = training_loop(model, optimizer, loss_fn, dataset, steps=100)"
      ],
      "metadata": {
        "id": "GTXdCOR-UXNI"
      },
      "id": "GTXdCOR-UXNI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plot_loss_curve(losses)"
      ],
      "metadata": {
        "id": "7_MjG_yrVRKd"
      },
      "id": "7_MjG_yrVRKd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plot_predictions(model, dataset)"
      ],
      "metadata": {
        "id": "wB1hEqs6U7qF"
      },
      "id": "wB1hEqs6U7qF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see we might be getting some reasonable predictions now. An interesting question to ask is what does the model predict across the entire domain i.e. outside of the spirals?"
      ],
      "metadata": {
        "id": "P14DDAiyZVp9"
      },
      "id": "P14DDAiyZVp9"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_spiral_classification(\n",
        "  model,\n",
        "  dataset,\n",
        "  grid_range=(-25, 25),\n",
        "  grid_size=500,\n",
        "  levels=10,\n",
        "):\n",
        "  \"\"\"\n",
        "  Plot model predictions over the 2D spiral input space alongside the true data points.\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  # Create meshgrid over specified range\n",
        "  x_min, x_max = grid_range\n",
        "  y_min, y_max = grid_range\n",
        "  xx, yy = torch.meshgrid(\n",
        "      torch.linspace(x_min, x_max, grid_size),\n",
        "      torch.linspace(y_min, y_max, grid_size),\n",
        "      indexing='ij'\n",
        "  )\n",
        "  grid = torch.stack([xx.flatten(), yy.flatten()], dim=1)\n",
        "\n",
        "  # Predict probabilities on grid\n",
        "  with torch.no_grad():\n",
        "      logits = model(grid)\n",
        "      probs = torch.sigmoid(logits).reshape(xx.shape).cpu().numpy()\n",
        "\n",
        "  # Plot contour of predicted probabilities\n",
        "  fig, ax = plt.subplots(figsize=(6, 6))\n",
        "  contour = ax.contourf(\n",
        "      xx.cpu().numpy(), yy.cpu().numpy(), probs,\n",
        "      levels=levels, cmap=\"RdBu\", alpha=0.50\n",
        "  )\n",
        "\n",
        "  # Overlay true data points\n",
        "  X_data = dataset.x.cpu().numpy()\n",
        "  y_data = dataset.y.squeeze().cpu().numpy()\n",
        "  ax.scatter(\n",
        "      X_data[:, 0], X_data[:, 1],\n",
        "      c=y_data, cmap=\"RdBu\", edgecolor='k', label='Ground Truth'\n",
        "  )\n",
        "\n",
        "  ax.set_title(\"Spiral Classification\")\n",
        "  ax.set_xlim(x_min, x_max)\n",
        "  ax.set_ylim(y_min, y_max)\n",
        "  ax.set_xlabel(r\"$x_0$\")\n",
        "  ax.set_ylabel(r\"$x_1$\")\n",
        "  ax.set_aspect(\"equal\")\n",
        "  ax.legend(loc=\"best\")\n",
        "  plt.tight_layout()\n",
        "  return fig, ax\n"
      ],
      "metadata": {
        "id": "YzUF3R-3ZiCO"
      },
      "id": "YzUF3R-3ZiCO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plot_spiral_classification(model, dataset)"
      ],
      "metadata": {
        "id": "xNl0TaT9aPzt"
      },
      "id": "xNl0TaT9aPzt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can think about what we're asking the network to do here, and how this shapes what it learns. We can think of the network as learning a height function (a surface) over the 2D input plane:\n",
        "\n",
        "\\begin{align*}\n",
        "  y = f(x_{0}, x_{1})\n",
        "\\end{align*}\n",
        "\n",
        "In its raw form, the spirals are not linearly separable - theres no straight line we can draw to separate the classes. But, once we ‚Äúlift‚Äù each point up to its height $y$, the spirals trace out two separate ridges on the surface. A simple horizontal cut‚Äîsay at $y = 0.5$ now cleanly slices the surface into two regions, each containing exactly one spiral. This enables classification.\n",
        "\n"
      ],
      "metadata": {
        "id": "WrcJ_mFqgLY2"
      },
      "id": "WrcJ_mFqgLY2"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
        "\n",
        "def plot_spiral_classification_3d(\n",
        "    model,\n",
        "    dataset,\n",
        "    grid_range=(-25, 25),\n",
        "    grid_size=500,\n",
        "    cmap=\"RdBu\",\n",
        "    alpha=0.8,\n",
        "    point_size=20\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot model predictions as a 3D surface over the 2D spiral input space,\n",
        "    with true data points projected onto the surface.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # 1) Create meshgrid\n",
        "    x_min, x_max = grid_range\n",
        "    y_min, y_max = grid_range\n",
        "    xx = np.linspace(x_min, x_max, grid_size)\n",
        "    yy = np.linspace(y_min, y_max, grid_size)\n",
        "    XX, YY = np.meshgrid(xx, yy)\n",
        "    grid = np.stack([XX.ravel(), YY.ravel()], axis=1)\n",
        "    grid_t = torch.tensor(grid, dtype=torch.float32)\n",
        "\n",
        "    # 2) Predict\n",
        "    with torch.no_grad():\n",
        "        logits = model(grid_t)\n",
        "        probs = torch.sigmoid(logits).cpu().numpy().reshape(XX.shape)\n",
        "\n",
        "    # 3) Plot\n",
        "    fig = plt.figure(figsize=(8, 6))\n",
        "    ax = fig.add_subplot(111, projection=\"3d\")\n",
        "\n",
        "    # Surface\n",
        "    surf = ax.plot_surface(\n",
        "        XX, YY, probs,\n",
        "        rstride=5, cstride=5,\n",
        "        cmap=cmap, edgecolor='none', alpha=alpha\n",
        "    )\n",
        "\n",
        "    # Scatter data points at their true probabilities (0 or 1)\n",
        "    Xd = dataset.x.cpu().numpy()\n",
        "    yd = dataset.y.squeeze().cpu().numpy()\n",
        "    # Evaluate model at data points for actual height\n",
        "    with torch.no_grad():\n",
        "        dp = torch.sigmoid(model(dataset.x)).cpu().numpy().squeeze()\n",
        "    ax.scatter(\n",
        "        Xd[:, 0], Xd[:, 1], dp,\n",
        "        c=yd, cmap=\"RdBu\",\n",
        "        edgecolor='k', s=point_size,\n",
        "        label=\"Data Predictions\"\n",
        "    )\n",
        "\n",
        "    ax.set_title(\"3D Spiral Classification Surface\")\n",
        "    ax.set_xlabel(\"$x_0$\")\n",
        "    ax.set_ylabel(\"$x_1$\")\n",
        "    ax.set_zlabel(\"Predicted Probability\")\n",
        "    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=10, label=\"P(class=1)\")\n",
        "    ax.view_init(elev=30, azim=-60)\n",
        "    plt.tight_layout()\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "fig, ax = plot_spiral_classification_3d(model, dataset)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2ssel3-agUcv"
      },
      "id": "2ssel3-agUcv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In other words, rather than trying to draw a winding curve in the plane, the network learns to warp the data into the third dimension so that a single flat plane can separate the classes. This is exactly analogous to how, in 1D, we use ReLU ‚Äúkinks‚Äù to approximate a curve by piecewise-linear segments: in 2D we use ReLU ‚Äúcreases‚Äù to build a surface whose level sets (planes $z = const.$) implement our decision boundary.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ds1qXrN7hFBF"
      },
      "id": "ds1qXrN7hFBF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In previous workshops we built up an understanding that each Perceptron learns a linear combination of its inputs and applies some non-linear activation function. We can investigate what each neuron is doing in this model too..."
      ],
      "metadata": {
        "id": "Z0_3vlB8hVth"
      },
      "id": "Z0_3vlB8hVth"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_layer_neuron_response(\n",
        "    model,\n",
        "    dataset,\n",
        "    layer_idx: int = 0,\n",
        "    neuron_idx: int = 0,\n",
        "    bounds: float = 25,\n",
        "    resolution: int = 500,\n",
        "    cmap: str = \"RdBu\",\n",
        "    alpha: float = 0.6\n",
        "):\n",
        "    \"\"\"\n",
        "    Visualize the activation of a single neuron in a given PerceptronLayer\n",
        "    over the 2D input plane.\n",
        "\n",
        "    Args:\n",
        "        model:          a MultiLayerPerceptron with .layers (ModuleList of PerceptronLayer)\n",
        "        dataset:        object with .x (Tensor[N,2]) and .y (Tensor[N,1])\n",
        "        layer_idx:      index into model.layers to probe\n",
        "        neuron_idx:     which output neuron of that layer to visualize\n",
        "        bounds:         axes range [-bounds, +bounds]\n",
        "        resolution:     number of grid points per axis\n",
        "        cmap:           heatmap colormap\n",
        "        alpha:          heatmap transparency\n",
        "    Returns:\n",
        "        fig, ax:        Matplotlib figure and axes\n",
        "    \"\"\"\n",
        "    assert hasattr(model, \"layers\"), \"Model must have a .layers attribute\"\n",
        "    assert 0 <= layer_idx < len(model.layers), f\"layer_idx out of range [0, {len(model.layers)-1}]\"\n",
        "\n",
        "    model.eval()\n",
        "    # 1) build grid\n",
        "    xs = torch.linspace(-bounds, bounds, resolution)\n",
        "    ys = torch.linspace(-bounds, bounds, resolution)\n",
        "    xx, yy = torch.meshgrid(xs, ys, indexing=\"ij\")\n",
        "    grid = torch.stack([xx.flatten(), yy.flatten()], dim=1)  # [res^2, 2]\n",
        "\n",
        "    # 2) forward through layers up to layer_idx\n",
        "    with torch.no_grad():\n",
        "        h = grid\n",
        "        for i, layer in enumerate(model.layers):\n",
        "            h = layer(h)\n",
        "            if i == layer_idx:\n",
        "                break\n",
        "        activations = h[:, neuron_idx].reshape(xx.shape).cpu().numpy()\n",
        "\n",
        "    # 3) plot\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    pcm = ax.contourf(\n",
        "        xx.cpu().numpy(),\n",
        "        yy.cpu().numpy(),\n",
        "        activations,\n",
        "        levels=50,\n",
        "        cmap=cmap,\n",
        "        alpha=alpha\n",
        "    )\n",
        "    fig.colorbar(pcm, ax=ax, label=f\"Layer {layer_idx} Neuron {neuron_idx} Activation\")\n",
        "\n",
        "    # overlay data\n",
        "    X_data = dataset.x.cpu().numpy()\n",
        "    y_data = dataset.y.squeeze().cpu().numpy()\n",
        "    ax.scatter(\n",
        "        X_data[:, 0], X_data[:, 1],\n",
        "        c=y_data, cmap=cmap,\n",
        "        edgecolor=\"k\", s=15, label=\"Data\"\n",
        "    )\n",
        "\n",
        "    ax.set_title(f\"Activation of Neuron {neuron_idx} in Layer {layer_idx}\")\n",
        "    ax.set_xlim(-bounds, bounds)\n",
        "    ax.set_ylim(-bounds, bounds)\n",
        "    ax.set_xlabel(\"$x_0$\")\n",
        "    ax.set_ylabel(\"$x_1$\")\n",
        "    ax.set_aspect(\"equal\")\n",
        "    ax.legend(loc=\"best\")\n",
        "    plt.tight_layout()\n",
        "    return fig, ax\n",
        "\n",
        "fig, ax = plot_layer_neuron_response(\n",
        "    model=model,\n",
        "    dataset=dataset,\n",
        "    layer_idx=1,\n",
        "    neuron_idx=5,\n",
        ")"
      ],
      "metadata": {
        "id": "qPbqNfJr_C2p"
      },
      "id": "qPbqNfJr_C2p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a $D$ dimensional input space, an MLP with ReLU activations alternates linear projections (affine mappings h=Wx+b) with folds (ReLU clamps along each coordinate‚Äôs hyperplane). This composition partitions $\\mathbb{R}^{D}$ into a mosaic of convex polytopes, within each of which the network's overall mapping is exactly affine. By stacking many project-and-fold layers, deep nets ‚Äúuntangle‚Äù complex manifolds so that a single final hyperplane can cleanly separate the classes."
      ],
      "metadata": {
        "id": "UPfG1byjj17l"
      },
      "id": "UPfG1byjj17l"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*An aside on manifolds...*\n",
        "\n",
        "Real-world data‚Äîwhether images, audio, or text‚Äîrarely fills its high-dimensional input space uniformly. Instead, it lies on a much lower-dimensional manifold, a ‚Äúsurface‚Äù defined by the data's true degrees of freedom.\n",
        "\n",
        "Learning this manifold means discovering that hidden subspace so that the model focuses on the essential structure (e.g. semantic content or object shape) rather than irrelevant variation.\n",
        "\n",
        "Deep networks uncover and flatten these manifolds by alternating linear projections (which lift data into new feature spaces) and nonlinear folds (ReLU or similar activations that crease along hyperplanes). Once the manifold is well represented, downstream tasks‚Äîclassification, regression, or generation‚Äîboil down to simple geometric operations (like slicing with a hyperplane or interpolating along the surface) in that learned feature space."
      ],
      "metadata": {
        "id": "qw8hZu1Qk82S"
      },
      "id": "qw8hZu1Qk82S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 1F. How does class noise impact performance?</h3>"
      ],
      "metadata": {
        "id": "Mu2NhqPIkNut"
      },
      "id": "Mu2NhqPIkNut"
    },
    {
      "cell_type": "markdown",
      "source": [
        "When class manifolds occupy distinct, well-separated regions‚Äîlike two spirals winding far apart‚Äîa simple boundary suffices and even a simple MLP can separate them.\n",
        "\n",
        "But when classes lie in close proximity or overlap on the manifold - imagine trying to classify different types of cars versus dogs and cars - the model must learn much more complex, nonlinear decision surfaces to untangle and distinguish them.\n",
        "\n",
        "We can imagine we have noise in our dataset which means the decision boundary is much tighter. Or perhaps we don't have classes that we can truly separate."
      ],
      "metadata": {
        "id": "xlN_1BVMG-Rk"
      },
      "id": "xlN_1BVMG-Rk"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SpiralDataset(N=500, noise=1.50)\n",
        "model = PointClassificationMultiLayerPerceptron(hidden_layers=0, hidden_dim=10)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "model, losses = training_loop(model, optimizer, loss_fn, dataset, steps=500)"
      ],
      "metadata": {
        "id": "vsNnn-SpHtKD"
      },
      "id": "vsNnn-SpHtKD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plot_spiral_classification(model, dataset)"
      ],
      "metadata": {
        "id": "sRPIrS4ZmCEL"
      },
      "id": "sRPIrS4ZmCEL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before we can observe how the network learns to interpolate in regions where the model has been less constrained. When you remove a region from the training set, the MLP has no information about how the classes behave there...\n",
        "\n",
        "üí¨ *Given the model learned is a function of the model x dataset x optimization, what techniques could you use to address this issue?*"
      ],
      "metadata": {
        "id": "3I9H2-GAHuR0"
      },
      "id": "3I9H2-GAHuR0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 1G. How well does the model interpolate?</h3>\n",
        "\n",
        "We can remove a portion of the training data to investigate how sensitive the model performance is to poor coverage of the underlying data manifold. We expect that without data to constrain the function behaviour within the removed region, the ability for the model to interpolate will depend on the geometry of the data manifold - for large changes we expect it to approximate poorly - for small changes we expect it to approximate reasonably."
      ],
      "metadata": {
        "id": "z16W8aqDOoN3"
      },
      "id": "z16W8aqDOoN3"
    },
    {
      "cell_type": "code",
      "source": [
        "# build dataset\n",
        "dataset_full = SpiralDataset(N=500, noise=0.2)\n",
        "x_full, y_full = dataset_full.x, dataset_full.y.squeeze()\n",
        "theta = torch.atan2(x_full[:,1], x_full[:,0])\n",
        "\n",
        "# pick a center and width\n",
        "theta_c = 0.75  # radians\n",
        "delta   = np.pi/10  # 22.5¬∞ on each side ‚Üí 45¬∞ total wedge\n",
        "\n",
        "# define masks\n",
        "wedge_mask = (theta > theta_c - delta) & (theta < theta_c + delta)\n",
        "class0 = (y_full == 0)\n",
        "class1 = (y_full == 1)\n",
        "\n",
        "# for *both* classes:\n",
        "train_mask  = (class0 & ~wedge_mask) | class1\n",
        "interp_mask = class0 & wedge_mask\n",
        "\n",
        "# split the dataset up\n",
        "class SubsetDataset:\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "train_ds  = SubsetDataset(dataset_full.x[train_mask],  dataset_full.y[train_mask])\n",
        "interp_ds = SubsetDataset(dataset_full.x[interp_mask], dataset_full.y[interp_mask])\n",
        "\n",
        "# train a model\n",
        "model     = PointClassificationMultiLayerPerceptron(hidden_layers=1, hidden_dim=10)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn   = nn.BCEWithLogitsLoss()\n",
        "model, losses = training_loop(model, optimizer, loss_fn, train_ds, steps=500)"
      ],
      "metadata": {
        "id": "yJiGKV0xnWm5"
      },
      "id": "yJiGKV0xnWm5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plot_loss_curve(losses)"
      ],
      "metadata": {
        "id": "AYC3fc8am948"
      },
      "id": "AYC3fc8am948",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plot_spiral_classification(\n",
        "    model,\n",
        "    train_ds,\n",
        "    grid_range=(-25,25),\n",
        "    grid_size=500,\n",
        "    levels=10\n",
        ")\n",
        "X_int = interp_ds.x.cpu().numpy()\n",
        "y_int = interp_ds.y.squeeze().cpu().numpy()\n",
        "ax.scatter(\n",
        "    X_int[:, 0], X_int[:, 1],\n",
        "    c=y_int, cmap=\"RdBu\",\n",
        "    marker=\"o\", edgecolor=\"yellow\",\n",
        "    s=50, label=\"Held-out wedge\", alpha=0.25\n",
        ")\n",
        "ax.set_title(\"Decision Boundary + Held-out Angular Wedge\")\n",
        "ax.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H7tr5OXw_8oH"
      },
      "id": "H7tr5OXw_8oH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 1H. How well does the model extrapolate?</h3>\n",
        "\n",
        "Because ReLU networks partition space into a finite set of polytopes defined by training-time hyperplanes, any point outside the convex hull of your data simply lands in one of those outermost pieces. The network then applies the same learned affine parameters on that piece, which can lead to constant or unbounded growth (depending on the weights) and typically very poor accuracy.\n",
        "\n",
        "In short, without explicit inductive biases or data covering the extrapolation region, deep nets have no guarantees and tend to perform arbitrarily poorly when asked to extrapolate.\n",
        "\n",
        "To investigate this we might consider extending the spirals..."
      ],
      "metadata": {
        "id": "a0iMsyRUITb7"
      },
      "id": "a0iMsyRUITb7"
    },
    {
      "cell_type": "code",
      "source": [
        "# build dataset\n",
        "dataset_extrap = SpiralDataset(N=1000, noise=0.2, ratio=1.25)\n",
        "\n",
        "# plot\n",
        "fig, ax = plot_spiral_classification(\n",
        "    model,\n",
        "    dataset_extrap,\n",
        "    grid_range=(-25,25),\n",
        "    grid_size=500,\n",
        "    levels=10\n",
        ")"
      ],
      "metadata": {
        "id": "-YLmJwTpIZDc"
      },
      "id": "-YLmJwTpIZDc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí¨ *Given the model learned is a function of the model x dataset x optimization, what techniques could you use to address this issue?*"
      ],
      "metadata": {
        "id": "BTXZY9i8Pa_p"
      },
      "id": "BTXZY9i8Pa_p"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 1I. How well does the model extrapolate? Again.</h3>\n",
        "\n",
        "When you deploy a model on data whose distribution differs from what it saw during training ‚Äî whether that's a different input range, noise level, or entirely new patterns ‚Äî you have zero theoretical guarantees that its piecewise-affine approximation will hold.\n",
        "\n",
        "In practice, the network will simply apply its learned affine maps to whichever region of its input tessellation the new points fall into, often resulting in unpredictable or completely wrong outputs under distribution shift.\n",
        "\n",
        "To investigate this we might consider flipping the spirals around $x_{0}=0$..."
      ],
      "metadata": {
        "id": "v_3AsSHGIfia"
      },
      "id": "v_3AsSHGIfia"
    },
    {
      "cell_type": "code",
      "source": [
        "# build dataset\n",
        "dataset_ood = SpiralDataset(N=1000, noise=0.2, ratio=1.25)\n",
        "\n",
        "# flip spiral\n",
        "dataset_ood.x[:,0] *= -1 # flip x-coord\n",
        "\n",
        "# plot\n",
        "fig, ax = plot_spiral_classification(\n",
        "    model,\n",
        "    dataset_ood,\n",
        "    grid_range=(-25,25),\n",
        "    grid_size=500,\n",
        "    levels=10\n",
        ")"
      ],
      "metadata": {
        "id": "ynwoJ2tP3FVh"
      },
      "id": "ynwoJ2tP3FVh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí¨ *Given the model learned is a function of the model x dataset x optimization, what techniques could you use to address this issue?*"
      ],
      "metadata": {
        "id": "PCzDfPx2Pthg"
      },
      "id": "PCzDfPx2Pthg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "One approach to reduce this issue might be data augmentation. Data augmentation refers to the practice of artificially expanding the dataset (by applying label-preserving transformations) to existing examples. The aim would be to expose the model to a wider data distribution so we hope we are more likely to be operating in the interpolation regime during inference.\n",
        "\n",
        "We might decide to train our model on randomly flipped spiral points..."
      ],
      "metadata": {
        "id": "TM6OserbD81y"
      },
      "id": "TM6OserbD81y"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Instantiate your dataset\n",
        "dataset = SpiralDataset(N=200, noise=0.2)\n",
        "\n",
        "# 2) Extract numpy arrays\n",
        "X = dataset.x.numpy()          # shape [400, 2]\n",
        "y = dataset.y.numpy().squeeze() # shape [400]\n",
        "\n",
        "# 3) Randomly choose half the points to flip\n",
        "flip_mask = np.random.rand(len(X)) < 0.5\n",
        "X_flipped = X.copy()\n",
        "X_flipped[flip_mask, 0] *= -1\n",
        "\n",
        "# 4) Plot original vs. randomly flipped\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
        "\n",
        "ax1.scatter(X[:, 0], X[:, 1], c=y, cmap=\"coolwarm\", edgecolor=\"k\", s=20)\n",
        "ax1.set_title(\"Original Spiral\")\n",
        "ax1.set_xlabel(\"$x_0$\")\n",
        "ax1.set_ylabel(\"$x_1$\")\n",
        "ax1.set_aspect(\"equal\")\n",
        "\n",
        "ax2.scatter(X_flipped[:, 0], X_flipped[:, 1], c=y, cmap=\"coolwarm\", edgecolor=\"k\", s=20)\n",
        "ax2.set_title(\"Randomly Flipped Points (50%)\")\n",
        "ax2.set_xlabel(\"$x_0$\")\n",
        "ax2.set_aspect(\"equal\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ucgn5hBKkMVO"
      },
      "id": "Ucgn5hBKkMVO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation only helps when the transformations you apply preserve the true label for each input. In our spiral example, an MLP sees only individual points $(x_{0}, x_{1})$ and never ‚Äúknows‚Äù how they connect into spirals. If you rotate or warp points arbitrarily, you'll send some points from spiral A into regions that really belong to spiral B‚Äîso the model gets conflicting examples (same transformed coordinates, different labels), which actually hurts learning rather than helps.\n",
        "\n",
        "To make augmentation effective here, you'd need label-preserving transforms that respect the spiral's geometry‚Äîlike small random jitters along the curve or slight radial scalings that keep points on the same arm. Alternatively, you must give the model global context (e.g. by encoding relative positions along the curve or using sequence-based encoders) so it can distinguish augmented points by where they fall on the overall spiral, not just by their local coordinates.\n",
        "\n",
        "> Effective problem formulation in machine learning means that your choice of inputs, outputs, model architecture, and data processing steps are all deeply interdependent, and each decision you make shapes what and how the model learns."
      ],
      "metadata": {
        "id": "EPlGZvI1lQGL"
      },
      "id": "EPlGZvI1lQGL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí¨ *How do you use data augmentation in your own research? What specific biases are you hoping to incorporate into your model by doing so?*"
      ],
      "metadata": {
        "id": "ctNA2uP_l1zV"
      },
      "id": "ctNA2uP_l1zV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Section 1G. Mini-batch Gradient Descent</h3>\n",
        "\n",
        "Mini-batch gradient descent is an optimization technique that updates model parameters using the average gradient computed over a small, randomly sampled subset of the training data (the \"mini-batch\") at each step.\n",
        "\n",
        "By processing, say, 32 - 256 examples at once, it leverages parallel hardware for efficiency, smooths out the high variance of per-example updates found in pure stochastic gradient descent, and still retains enough randomness to help escape poor local minima‚Äîunlike full batch methods, which compute gradients over the entire dataset and can be prohibitively slow or memory-intensive on large datasets.\n",
        "\n",
        "When we perform the gradient descent step:\n",
        "\n",
        "\\begin{align*}\n",
        "\\theta := \\theta - \\eta \\cdot \\nabla_\\theta \\mathcal{L}(f_\\theta(x), y)\n",
        "\\end{align*}\n",
        "\n",
        "We compute the loss across a subset of the dataset per step:\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathcal{L}(\\theta)\n",
        "= \\frac{1}{M} \\sum_{i=1}^{M} \\left( f_\\theta(x_i) - y_i \\right)^2\n",
        "\\end{align*}\n",
        "\n",
        "where:\n",
        "\n",
        "\\begin{align*}\n",
        "    \\mathcal{D} = \\left\\{ (\\mathcal{X}_{i}, \\mathcal{Y}_{i}) \\right\\}_{i=0}^{M} \\subseteq \\left\\{ (\\mathcal{X}_{i}, \\mathcal{Y}_{i}) \\right\\}_{i=0}^{N}\n",
        "\\end{align*}\n",
        "\n",
        "As your batch size decreases your approximation of the loss landscape becomes worse, and thus your gradient becomes worse. This acts as a regularizing effect during training potentially reducing over-fitting, on the extreme end it can make training extremely difficult.\n",
        "\n",
        "> You're blindfolded and attempting to navigate downhill and the landscape changes each step you take."
      ],
      "metadata": {
        "id": "qRBzBYkSC1AV"
      },
      "id": "qRBzBYkSC1AV"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1) Instantiate your dataset\n",
        "dataset = SpiralDataset(N=500, noise=0.20)\n",
        "\n",
        "# 2) Prepare a dataloader (e.g. batch size 100)\n",
        "batch_size = 100\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 3) Grab one batch\n",
        "batch_x, batch_y = next(iter(dataloader))\n",
        "\n",
        "# 4) Convert to NumPy for plotting\n",
        "full_x = dataset.x.cpu().numpy()\n",
        "full_y = dataset.y.squeeze().cpu().numpy()\n",
        "bx     = batch_x.cpu().numpy()\n",
        "by     = batch_y.squeeze().cpu().numpy()\n",
        "\n",
        "# 5) Plot\n",
        "fig, (ax_full, ax_batch) = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
        "\n",
        "# Full dataset\n",
        "ax_full.scatter(full_x[:, 0], full_x[:, 1], c=full_y,\n",
        "                cmap=\"coolwarm\", edgecolor=\"k\", s=20)\n",
        "ax_full.set_title(\"Full Spiral Dataset\")\n",
        "ax_full.set_xlabel(\"$x_0$\")\n",
        "ax_full.set_ylabel(\"$x_1$\")\n",
        "ax_full.set_aspect(\"equal\")\n",
        "\n",
        "# Single batch\n",
        "ax_batch.scatter(bx[:, 0], bx[:, 1], c=by,\n",
        "                 cmap=\"coolwarm\", edgecolor=\"k\", s=20)\n",
        "ax_batch.set_title(f\"Single Batch (size={batch_size})\")\n",
        "ax_batch.set_xlabel(\"$x_0$\")\n",
        "ax_batch.set_aspect(\"equal\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3ryIotpEDW9w"
      },
      "id": "3ryIotpEDW9w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to modify our training loop slightly to handle using batches, we will use the `DataLoader` class to handle this for us..."
      ],
      "metadata": {
        "id": "gS6Ls3d5MqWv"
      },
      "id": "gS6Ls3d5MqWv"
    },
    {
      "cell_type": "code",
      "source": [
        "# define a training loop\n",
        "def training_loop_epochs(model, optimizer, loss_fn, dataloader, epochs):\n",
        "  losses = []\n",
        "  with tqdm(range(epochs)) as pbar:\n",
        "    for idx in pbar:\n",
        "      for jdx, batch in enumerate(dataloader): # each step represents a subset of the dataset\n",
        "        optimizer.zero_grad()\n",
        "        x, y = batch\n",
        "        y_pred = model(x)\n",
        "        # print(jdx, x.shape, y.shape)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        losses.append(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(f\"[Epoch:{idx+1}/{epochs}] loss @ step {jdx}: {loss.item():.3f}\")\n",
        "  return model, torch.tensor(losses)"
      ],
      "metadata": {
        "id": "I2-slj2qMtA4"
      },
      "id": "I2-slj2qMtA4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compute the number of epochs by dividing our desired total update count `n_steps` by the number of batches per epoch `N//bs`, so that we perform approximately the same number of update steps as during previous training. Explore how the batch size impacts the performance of the model."
      ],
      "metadata": {
        "id": "ELF6j_qmHJXF"
      },
      "id": "ELF6j_qmHJXF"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset = SpiralDataset(N=200, noise=0.20)\n",
        "\n",
        "# compute the equivalent number of epochs to use\n",
        "n_steps = 500\n",
        "n_samples = len(dataset) # should be 2*N\n",
        "bs = 32\n",
        "n_epochs = n_steps // (n_samples // bs)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=bs, shuffle=False, drop_last=True)\n",
        "model = PointClassificationMultiLayerPerceptron(hidden_layers=1, hidden_dim=10)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "model, losses = training_loop_epochs(model, optimizer, loss_fn, dataloader, epochs=n_epochs)"
      ],
      "metadata": {
        "id": "DyHpIb3mC6vC"
      },
      "id": "DyHpIb3mC6vC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plot_loss_curve(losses)"
      ],
      "metadata": {
        "id": "1M2bKMRvJyLE"
      },
      "id": "1M2bKMRvJyLE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plot_spiral_classification(model, dataset)"
      ],
      "metadata": {
        "id": "yLfVbScTEWEl"
      },
      "id": "yLfVbScTEWEl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Conclusion</h2>\n",
        "\n",
        "This workshop emphasized how machine learning is more than just model training ‚Äî it is a process of designing learning systems. Every decision and component we use and define encodes assumptions and inductive biases into these systems. The formulation of the problem, the representation of the data, the structure of the model, and the optimization strategy all interact to determine what the model learns.\n",
        "\n",
        "\n",
        "<h3>‚úÖ Takeaways</h3>\n",
        "\n",
        "**From Function Approximation to Classification**: Revisited key ML concepts (hypothesis space, data, optimization), explored universal function approximation with MLPs, and evaluated interpolation vs. extrapolation behaviour.\n",
        "\n",
        "**Problem Formulation & Representation**: Investigated how the structure of a learning problem (e.g., spiral classification) and the representation of inputs (point clouds, images, graphs) affect the choice of model and solution space.\n",
        "\n",
        "**Designing & Evaluating Learning Systems**: Built and trained classification models, visualized their decision surfaces, studied robustness to noise and missing data, and examined limits of generalization through controlled experiments."
      ],
      "metadata": {
        "id": "nsziYpdUbx-P"
      },
      "id": "nsziYpdUbx-P"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> We hope you have gained an appreciation both the core mechanisms of deep learning and the trade-offs in designing learning systems."
      ],
      "metadata": {
        "id": "wmBMD8_smx4K"
      },
      "id": "wmBMD8_smx4K"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1tGTNSgcfgec"
      },
      "id": "1tGTNSgcfgec",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}